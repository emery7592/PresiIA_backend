"""
Centralise la configuration commune au module chat avec RAG.
"""
import os
import json
from pathlib import Path
from dotenv import load_dotenv
from openai import OpenAI
from pypdf import PdfReader
import numpy as np
from sentence_transformers import SentenceTransformer
import faiss
from typing import List, Dict, Tuple
from dataclasses import dataclass

# ‚îÄ‚îÄ Configuration g√©n√©rale ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
load_dotenv(override=True)
BASE_DIR = Path(__file__).resolve().parent.parent
STATIC_DIR = BASE_DIR / "static" / "document"
PDF_PATH = STATIC_DIR / "specpense.pdf"

# ‚îÄ‚îÄ Clients externes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
openai_client = OpenAI()
PUSHOVER_USER = os.getenv("PUSHOVER_USER")
PUSHOVER_TOKEN = os.getenv("PUSHOVER_TOKEN")
PUSHOVER_URL = "https://api.pushover.net/1/messages.json"

# ‚îÄ‚îÄ Syst√®me RAG ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

@dataclass
class DocumentChunk:
    content: str
    page_number: int
    chunk_id: int

class SimpleRAG:
    """Version simplifi√©e du syst√®me RAG pour ton cas d usage."""
    
    def __init__(self, pdf_path: str):
        self.pdf_path = pdf_path
        self.chunks: List[DocumentChunk] = []
        self.embeddings = None
        self.index = None
        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
        
    def extract_and_chunk_pdf(self, chunk_size: int = 400) -> List[DocumentChunk]:
        """Extrait et d√©coupe le PDF en chunks."""
        reader = PdfReader(self.pdf_path)
        chunks = []
        chunk_id = 0
        
        for page_num, page in enumerate(reader.pages):
            text = page.extract_text() or ""
            words = text.split()
            
            # D√©coupage en chunks
            for i in range(0, len(words), chunk_size):
                chunk_words = words[i:i + chunk_size]
                chunk_content = " ".join(chunk_words)
                
                if len(chunk_content.strip()) > 50:  # √âviter les chunks trop petits
                    chunk = DocumentChunk(
                        content=chunk_content,
                        page_number=page_num + 1,
                        chunk_id=chunk_id
                    )
                    chunks.append(chunk)
                    chunk_id += 1
        
        self.chunks = chunks
        return chunks
    
    def build_embeddings(self):
        """G√©n√®re les embeddings pour tous les chunks."""
        print(f"üîÑ G√©n√©ration des embeddings pour {len(self.chunks)} chunks...")
        
        texts = [chunk.content for chunk in self.chunks]
        embeddings = self.embedding_model.encode(texts, show_progress_bar=True)
        
        # Cr√©ation de l index FAISS
        dimension = embeddings.shape[1]
        self.index = faiss.IndexFlatIP(dimension)
        
        # Normalisation pour similarit√© cosinus
        faiss.normalize_L2(embeddings)
        self.index.add(embeddings.astype('float32'))
        
        self.embeddings = embeddings
        print(f"‚úÖ Index FAISS cr√©√© avec {self.index.ntotal} vecteurs")
    
    def search_relevant_chunks(self, query: str, top_k: int = 5) -> List[Tuple[DocumentChunk, float]]:
        """Recherche les chunks les plus pertinents."""
        if self.index is None:
            raise ValueError("Index non cr√©√©. Appelez build_embeddings() d abord.")
        
        query_embedding = self.embedding_model.encode([query])
        faiss.normalize_L2(query_embedding)
        
        scores, indices = self.index.search(query_embedding.astype('float32'), top_k)
        
        results = []
        for score, idx in zip(scores[0], indices[0]):
            if idx < len(self.chunks):
                results.append((self.chunks[idx], float(score)))
        
        return results
    
    def get_context_for_query(self, query: str, max_chars: int = 8000) -> str:
        """R√©cup√®re le contexte pertinent pour une query."""
        relevant_chunks = self.search_relevant_chunks(query, top_k=8)
        
        context_parts = []
        total_chars = 0
        
        for chunk, score in relevant_chunks:
            chunk_text = f"[Page {chunk.page_number}]\n{chunk.content}\n"
            
            if total_chars + len(chunk_text) <= max_chars:
                context_parts.append(chunk_text)
                total_chars += len(chunk_text)
            else:
                break
        
        return "\n---\n".join(context_parts)
    
    def save_index(self, base_path: str):
        """Sauvegarde l index."""
        faiss.write_index(self.index, f"{base_path}.faiss")
        
        chunks_data = []
        for chunk in self.chunks:
            chunks_data.append({
                'content': chunk.content,
                'page_number': chunk.page_number,
                'chunk_id': chunk.chunk_id
            })
        
        with open(f"{base_path}_chunks.json", 'w', encoding='utf-8') as f:
            json.dump(chunks_data, f, ensure_ascii=False, indent=2)
    
    def load_index(self, base_path: str):
        """Charge un index sauvegard√©."""
        self.index = faiss.read_index(f"{base_path}.faiss")
        
        with open(f"{base_path}_chunks.json", 'r', encoding='utf-8') as f:
            chunks_data = json.load(f)
        
        self.chunks = []
        for data in chunks_data:
            chunk = DocumentChunk(
                content=data['content'],
                page_number=data['page_number'],
                chunk_id=data['chunk_id']
            )
            self.chunks.append(chunk)

# ‚îÄ‚îÄ Initialisation du syst√®me RAG ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def initialize_rag():
    """Initialise le syst√®me RAG (une seule fois)."""
    index_path = BASE_DIR / "rag_index"
    
    rag = SimpleRAG(str(PDF_PATH))
    
    # V√©rifier si l index existe
    if (Path(f"{index_path}.faiss").exists() and 
        Path(f"{index_path}_chunks.json").exists()):
        print("üìö Chargement de l index RAG existant...")
        rag.load_index(str(index_path))
        print(f"‚úÖ Index charg√©: {len(rag.chunks)} chunks disponibles")
    else:
        print("üîÑ Cr√©ation du nouvel index RAG...")
        rag.extract_and_chunk_pdf()
        rag.build_embeddings()
        rag.save_index(str(index_path))
        print(f"‚úÖ Index RAG cr√©√©: {len(rag.chunks)} chunks")
    
    return rag

# Initialisation globale
RAG_SYSTEM = initialize_rag()

# ‚îÄ‚îÄ Syst√®me de d√©tection th√©matique ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def detect_query_theme(user_query: str) -> dict:
    """
    D√©tecte le th√®me de la question pour orienter vers les bons articles.
    Retourne un dictionnaire avec le th√®me d√©tect√© et des instructions sp√©ciales.
    """
    query_lower = user_query.lower()
    
    # Dictionnaire de d√©tection th√©matique avec mots-cl√©s √©largis
    themes = {
        'infidelite': {
            'keywords': ['infid√®le', 'infid√©lit√©', 'tromp√©', 'trompe', 'tromper', 'cocufi√©', 
                        'cocu', 'adult√®re', 'autre homme', 'autre femme', 'liaison', 
                        'triche', 'tricherie', 'attraper', 'flagrant d√©lit', 'pardon',
                        'pardonne', 'cheating', 'affair'],
            'requires_clarification': True,
            'clarification_question': "Juste pour √™tre s√ªr : parles-tu d une situation o√π ta partenaire t a √©t√© infid√®le ?",
            'article_trigger': "Article √† sortir concernant le pardon de l infid√©lit√©"
        },
        'femme_toxique': {
            'keywords': ['toxique', 'manipulatrice', 'narcissique', 'instable', 'clown', 
                        'cirque', 'd√©pendance', 'cod√©pendance', 'manipulation', 'victime',
                        'reste', 'retourne', 'revenir'],
            'article_trigger': "NE BL√ÇME PAS UN CLOWN"
        },
        'rupture_manipulation': {
            'keywords': ['rupture', 's√©paration', 'quitter', 'quitt√©', 'ex', 'cass√©', 
                        'victimisation', 'victimise', 'd√©responsabilisation'],
            'article_trigger': "COMMENT CERTAINES FEMMES MANIPULENT LES RUPTURES"
        },
        'femme_doit_aimer_plus': {
            'keywords': ['aimer plus', 'elle m aime', 'hypergamie', 'fid√©lit√©', 'loyaut√©',
                        'engagement', 'vision', 'progression'],
            'article_trigger': "EFFECTIVEMENT LA FEMME DOIT AIMER PLUS QUE L HOMME"
        },
        'femme_amortie': {
            'keywords': ['pass√©', 'ex toxic', 'choix destructeur', 'qualit√©', 'm√©rite',
                        'buisson d √©pines', 'homme toxique', 'maturit√©', 'd√©clin'],
            'article_trigger': "UN HOMME DE QUALIT√â NE M√âRITE PAS UNE FEMME AMORTIE"
        }
    }
    
    # D√©tection du th√®me
    for theme_name, theme_data in themes.items():
        for keyword in theme_data['keywords']:
            if keyword in query_lower:
                return {
                    'theme': theme_name,
                    'data': theme_data
                }
    
    return {'theme': None, 'data': None}

def is_greeting_or_intro(user_query: str) -> bool:
    """
    D√©tecte si c est un message de salutation ou une demande de pr√©sentation.
    """
    query_lower = user_query.lower().strip()
    
    # Mots et phrases cl√©s pour d√©tecter les pr√©sentations
    greetings = [
        'bonjour', 'salut', 'hello', 'hey', 'hi', 'bonsoir', 'coucou',
        'qui es-tu', 'qui es tu', 'c est quoi', 'pr√©sente-toi', 'pr√©sente toi',
        'tu es qui', 'tu fais quoi', 'what are you', 'who are you',
        'pourquoi toi', 'pourquoi je devrais', 'quelle diff√©rence', 
        'diff√©rence avec chatgpt', 'plutot qu une autre', 'plut√¥t qu une autre',
        'pourquoi pas chatgpt', 'en quoi tu es diff√©rent', 'utiliser toi',
        'autre ia', 'autre IA', 'chatgpt', 'chat gpt'
    ]
    
    # V√©rification des mots-cl√©s
    for greeting in greetings:
        if greeting in query_lower:
            return True
    
    # D√©tection de patterns sp√©cifiques
    presentation_patterns = [
        ('pourquoi' in query_lower and 'utiliser' in query_lower),
        ('pourquoi' in query_lower and 'toi' in query_lower),
        ('quelle' in query_lower and 'diff√©rence' in query_lower),
        ('autre' in query_lower and ('ia' in query_lower or 'IA' in user_query)),
        ('plutot' in query_lower or 'plut√¥t' in query_lower),
    ]
    
    if any(presentation_patterns):
        return True
    
    # Si le message est tr√®s court (moins de 20 caract√®res), probablement une salutation
    if len(query_lower) < 20 and any(word in query_lower for word in ['salut', 'hello', 'bonjour', 'hey', 'hi']):
        return True
    
    return False

# ‚îÄ‚îÄ Fonction de prompt intelligent ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def get_system_prompt(user_query: str = "") -> str:
    """G√©n√®re un prompt avec contexte adaptatif et d√©tection th√©matique."""
    name = "Ralph AI"
    
    # PRIORIT√â 1 : D√©tection des salutations et demandes de pr√©sentation
    if is_greeting_or_intro(user_query):
        # Pour les pr√©sentations, on retourne un prompt sp√©cial simplifi√©
        print("üëã Salutation/Pr√©sentation d√©tect√©e - Mode pr√©sentation activ√©")
        return f"""Tu es {name}, assistant sp√©cialis√© dans la philosophie redpill masculine.

## INSTRUCTION UNIQUE : MESSAGE DE PR√âSENTATION

L utilisateur te demande de te pr√©senter ou te compare √† d autres IA.

R√©ponds UNIQUEMENT avec ce message EXACT (adapt√© √† la langue de la question) :

"Excellente question ! üéØ

Les IA g√©n√©ralistes comme ChatGPT vous donnent des r√©ponses politiquement correctes qui ne servent √† rien. Moi, je vous dis la v√©rit√©, m√™me si elle d√©range.

Voici pourquoi je suis diff√©rent :

‚úÖ **La v√©rit√© avant le consensus** : Je n ai pas de filtre blue pill. Je vous explique les vraies dynamiques relationnelles, pas ce que la soci√©t√© veut entendre

‚úÖ **Expertise pure relations** : Sp√©cialis√© √† 100% dans les relations homme-femme, l attraction et la psychologie f√©minine. Pas de connaissances g√©n√©ralistes dilu√©es

‚úÖ **Strat√©gies qui marchent vraiment** : Des plans d action concrets bas√©s sur ce qui fonctionne r√©ellement, pas sur des th√©ories romantiques d√©connect√©es

Si vous en avez marre des conseils mi√®vres qui ne donnent aucun r√©sultat, je suis fait pour vous.

Pr√™t √† avoir des r√©ponses qui changent vraiment la donne ? üí™"

R√àGLES STRICTES :
- N AJOUTE RIEN d autre au message
- Utilise exactement ce texte
- Traduis dans la langue de la question si n√©cessaire (anglais, italien, espagnol, etc.)
- Ne mentionne PAS le document ou les relations homme-femme dans ce contexte
"""
    
    # PRIORIT√â 2 : D√©tection th√©matique pour les questions normales
    theme_detection = detect_query_theme(user_query)
    theme_instruction = ""
    
    if theme_detection['theme']:
        theme_data = theme_detection['data']
        
        # Cas sp√©cial : infid√©lit√© n√©cessite une clarification
        if theme_detection['theme'] == 'infidelite' and theme_data.get('requires_clarification'):
            theme_instruction = f"""
## INSTRUCTION SP√âCIALE D√âTECT√âE : INFID√âLIT√â
La question semble concerner l infid√©lit√©. 
AVANT de r√©pondre, tu DOIS poser cette question de clarification :
"{theme_data['clarification_question']}"

SI l utilisateur confirme qu il s agit d infid√©lit√© ‚Üí Utilise IMP√âRATIVEMENT l article "{theme_data['article_trigger']}" du document.
SI l utilisateur nie ‚Üí Traite la question normalement selon le contexte RAG.
"""
        else:
            # Autres th√®mes : orientation directe vers l article
            theme_instruction = f"""
## TH√àME D√âTECT√â : {theme_detection['theme'].upper()}
Cette question est li√©e √† l article "{theme_data['article_trigger']}".
Utilise PRIORITAIREMENT le contenu de cet article pour r√©pondre, m√™me si le RAG propose d autres chunks.
"""
    
    # G√©n√©ration du contexte RAG
    if user_query and user_query.strip():
        try:
            relevant_context = RAG_SYSTEM.get_context_for_query(user_query, max_chars=10000)
            print(f"üéØ Contexte RAG g√©n√©r√©: {len(relevant_context)} caract√®res")
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur RAG: {e}")
            relevant_context = "Contexte non disponible"
    else:
        relevant_context = "Pas de contexte n√©cessaire pour ce type de message"
    
    prompt = f"""Tu es {name}, assistant sp√©cialis√© dans la philosophie redpill masculine.

{theme_instruction}

## R√àGLES ABSOLUES (√† respecter imp√©rativement) :

1. **Orientation intelligente vers les articles** :
   - Comprends l INTENTION de la question, pas seulement les mots exacts
   - Si une question parle de "ma femme me trompe" ‚Üí c est l article sur l INFID√âLIT√â
   - Si une question parle de "femme manipulatrice que je revois" ‚Üí c est l article sur le CLOWN/CIRQUE
   - Si une question parle de "elle a cass√© avec moi" ‚Üí c est l article sur les RUPTURES MANIPUL√âES
   - Utilise le contexte RAG comme base, mais fais preuve d intelligence pour identifier le bon article

2. **R√©ponses bas√©es sur le document** :
   - Si la question est abord√©e dans specpense.pdf ‚Üí r√©ponds en utilisant EXCLUSIVEMENT le contenu du document
   - Cite les concepts et formules du texte (ex: "tu ne changes pas un clown, tu changes de cirque")
   - Ne mentionne JAMAIS les num√©ros de page

3. **Questions hors document** :
   - Si c est une question homme-femme/relations MAIS non couverte ‚Üí r√©ponds selon les principes redpill :
     * Responsabilit√© masculine
     * Anti-victimisation de l homme
     * Cadre et fronti√®res
     * Valeur personnelle avant la relation
   - Si ce N EST PAS une question homme-femme ‚Üí r√©ponds : "Cette question ne concerne pas les relations homme-femme. Je ne peux y r√©pondre."

4. **INTERDIT ABSOLU - Ne JAMAIS faire ceci** :
   ‚ùå Conseiller la "compr√©hension √©motionnelle excessive" de la femme
   ‚ùå Sugg√©rer que l homme doit "faire plus d efforts" pour une femme toxique
   ‚ùå Donner des r√©ponses "blue pill" : "communiquez davantage", "soyez √† l √©coute"
   ‚ùå Victimiser la femme ou d√©responsabiliser l homme
   ‚ùå Encourager un homme √† rester dans une relation destructrice
   ‚ùå Dire "essayez de comprendre ses besoins" ou "elle a peut-√™tre ses raisons"

5. **Ton et style** :
   - Direct, structur√©, masculin et ferme
   - Utilise les titres en MAJUSCULES du document si pertinent
   - Ferme mais JAMAIS insultant envers le client
   - Utilise les formules-chocs du texte (ex: "Il vaut mieux traverser nu un fleuve infest√© de piranhas...")

6. **Langue de r√©ponse** :
   - R√©ponds dans la M√äME LANGUE que la question
   - Fran√ßais ‚Üí fran√ßais, Anglais ‚Üí anglais, Italien ‚Üí italien, etc.

## EXEMPLES DE NAVIGATION INTELLIGENTE :

Question : "Ma copine m a tromp√© et demande pardon"
‚Üí Th√®me d√©tect√© : INFID√âLIT√â
‚Üí Action : Poser question de clarification puis utiliser l article sur le pardon de l infid√©lit√©

Question : "Je retourne toujours voir mon ex qui me manipule"
‚Üí Th√®me d√©tect√© : FEMME TOXIQUE / CIRQUE
‚Üí Action : Utiliser l article "NE BL√ÇME PAS UN CLOWN, INTERROGE TA PR√âSENCE AU CIRQUE"

Question : "Elle a cass√© et joue la victime partout"
‚Üí Th√®me d√©tect√© : RUPTURE MANIPULATION
‚Üí Action : Utiliser l article sur les 3 √©tapes de manipulation des ruptures

## EXEMPLES DE BONNES vs MAUVAISES R√âPONSES :

‚ùå MAUVAIS (blue pill) :
"Votre femme vous critique ? Essayez de comprendre d o√π viennent ses besoins √©motionnels. La communication est la cl√©..."

‚úÖ BON (redpill conforme au document) :
"Un homme fort √©tablit son cadre et ne n√©gocie pas son respect. Si elle critique constamment, c est un test de dominance. Tu ne changes pas un clown, tu changes de cirque."

---

## Contexte pertinent du document :
{relevant_context}

---

R√©ponds maintenant √† la question du client en suivant TOUTES ces r√®gles."""
    
    print(f"üìè Taille du prompt syst√®me : {len(prompt)} caract√®res")
    print(f"üéØ Th√®me d√©tect√© : {theme_detection['theme'] or 'Aucun'}")
    return prompt

# ‚îÄ‚îÄ Fonction de fallback ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def build_spec_summary_fallback() -> str:
    """Fallback vers l ancien syst√®me en cas de probl√®me."""
    reader = PdfReader(PDF_PATH)
    pages = [p.extract_text() or "" for p in reader.pages]
    full_text = "\n".join(pages)
    
    max_chars = 10000
    if len(full_text) > max_chars:
        truncated_text = full_text[:max_chars]
        truncated_text += "\n\n[... Document tronqu√© pour √©viter le d√©passement de tokens ...]"
        print(f"‚ö†Ô∏è Fallback: PDF tronqu√© de {len(full_text)} √† {len(truncated_text)} caract√®res")
        return truncated_text
    
    return full_text